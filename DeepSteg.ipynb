{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepSteg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adharshkamath/Deep-Steganography/blob/master/DeepSteg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SRozbeFY5v-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFQPYLNKo9Kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import functools\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqT0IheTq1Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, num_downs, ngf=64,\n",
        "                 norm_layer=nn.BatchNorm2d, use_dropout=False, output_function=nn.Sigmoid):\n",
        "        super(UnetGenerator, self).__init__()\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)\n",
        "        for i in range(num_downs - 5):\n",
        "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)\n",
        "\n",
        "        self.model = unet_block\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "class UnetSkipConnectionBlock(nn.Module):\n",
        "    def __init__(self, outer_nc, inner_nc, input_nc=None,submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False, output_function=nn.Sigmoid):\n",
        "        super(UnetSkipConnectionBlock, self).__init__()\n",
        "        self.outermost = outermost\n",
        "        if type(norm_layer) == functools.partial:\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "        if input_nc is None:\n",
        "            input_nc = outer_nc\n",
        "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
        "                             stride=2, padding=1, bias=use_bias)\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = norm_layer(inner_nc)\n",
        "        uprelu = nn.ReLU(True)\n",
        "        upnorm = norm_layer(outer_nc)\n",
        "\n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1)\n",
        "            down = [downconv]\n",
        "            if output_function == nn.Tanh:\n",
        "                up = [uprelu, upconv, nn.Tanh()]\n",
        "            else:\n",
        "                up = [uprelu, upconv, nn.Sigmoid()]\n",
        "            model = down + [submodule] + up\n",
        "        elif innermost:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1, bias=use_bias)\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1, bias=use_bias)\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "\n",
        "            if use_dropout:\n",
        "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
        "            else:\n",
        "                model = down + [submodule] + up\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:\n",
        "            return torch.cat([x, self.model(x)], 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yezT5s6K-M1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RevealNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RevealNet, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(128, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(256, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(128, 64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(64, 3, 3, 1, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, input):\n",
        "        output=self.main(input)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP31RiBxEf4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE3RF8lYN_zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_log(log_info, log_path, console=True):\n",
        "    print(log_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srkjNKNKrN33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_result_pic(this_batch_size, originalLabelv, ContainerImg, secretLabelv, RevSecImg, epoch, i, save_path):\n",
        "    originalFrames = originalLabelv.resize_(this_batch_size, 3, 256, 256)\n",
        "    containerFrames = ContainerImg.resize_(this_batch_size, 3, 256, 256)\n",
        "    secretFrames = secretLabelv.resize_(this_batch_size, 3,256, 256)\n",
        "    revSecFrames = RevSecImg.resize_(this_batch_size, 3, 256, 256)\n",
        "    showContainer = torch.cat([originalFrames, containerFrames], 0)\n",
        "    showReveal = torch.cat([secretFrames, revSecFrames], 0)\n",
        "    resultImg = torch.cat([showContainer, showReveal], 0)\n",
        "    resultImgName = '%s/ResultImage_epoch%03d_batch%04d.png' % (save_path, epoch, i)\n",
        "    vutils.save_image(resultImg, resultImgName, nrow=this_batch_size, padding=1, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlP_Nz7jg-j3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u2K1he4NYI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, epoch, Hnet, Rnet, criterion, epochs):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    Hlosses = AverageMeter() \n",
        "    Rlosses = AverageMeter() \n",
        "    SumLosses = AverageMeter()  \n",
        "\n",
        "    Hnet.train()\n",
        "    Rnet.train()\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "        data_time.update(time.time() - start_time)\n",
        "\n",
        "        Hnet.zero_grad()\n",
        "        Rnet.zero_grad()\n",
        "\n",
        "        all_pics, _ = batch_data \n",
        "        this_batch_size = int(all_pics.size()[0] / 2)  \n",
        "\n",
        "       \n",
        "        cover_img = all_pics[0:this_batch_size, :, :, :] \n",
        "        secret_img = all_pics[this_batch_size:this_batch_size * 2, :, :, :]\n",
        "\n",
        "        concat_img = torch.cat([cover_img, secret_img], dim=1)\n",
        "\n",
        "        if  torch.cuda.is_available():\n",
        "            cover_img = cover_img.cuda()\n",
        "            secret_img = secret_img.cuda()\n",
        "            concat_img = concat_img.cuda()\n",
        "\n",
        "        concat_imgv = Variable(concat_img)\n",
        "        cover_imgv = Variable(cover_img)\n",
        "\n",
        "        container_img = Hnet(concat_imgv) \n",
        "        errH = criterion(container_img, cover_imgv)\n",
        "        Hlosses.update(errH.item(), this_batch_size)\n",
        "\n",
        "        rev_secret_img = Rnet(container_img) \n",
        "        secret_imgv = Variable(secret_img)\n",
        "        errR = criterion(rev_secret_img, secret_imgv)  \n",
        "        Rlosses.update(errR.item(), this_batch_size)\n",
        "\n",
        "        betaerrR_secret = 0.75 * errR\n",
        "        err_sum = errH + betaerrR_secret\n",
        "        SumLosses.update(err_sum.item(), this_batch_size)\n",
        "\n",
        "        err_sum.backward()\n",
        "\n",
        "        optimizerH.step()\n",
        "        optimizerR.step()\n",
        "\n",
        "        batch_time.update(time.time() - start_time)\n",
        "        start_time = time.time()\n",
        "\n",
        "        log = '[%d/%d][%d/%d]\\tHnet Loss: %.4f\\tRnet Loss: %.4f\\tOverall loss: %.4f \\t datatime: %.4f \\t batchtime: %.4f' % (\n",
        "            epoch + 1, epochs, i, len(train_loader),\n",
        "            Hlosses.val, Rlosses.val, SumLosses.val, data_time.val, batch_time.val)\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            print(log)\n",
        "\n",
        "        if i % resultPicFrequency == 0:\n",
        "            save_result_pic(this_batch_size, cover_img, container_img.data, secret_img, rev_secret_img.data, epoch, i,\n",
        "                            trainpics)\n",
        "\n",
        "    epoch_log = \"----------------------------  one epoch time is %.4f  ----------------------------\" % (\n",
        "        batch_time.sum) + \"\\n\"\n",
        "    epoch_log = epoch_log + \"Learning rates: Hnet = %.8f      Rnet = %.8f\" % (\n",
        "        optimizerH.param_groups[0]['lr'], optimizerR.param_groups[0]['lr']) + \"\\n\"\n",
        "    epoch_log = epoch_log + \"Average Hnet Loss for the epoch=%.6f\\t Average Rnet Loss for the epoch=%.6f\\t Total Average loss for the epoch=%.6f\" % (\n",
        "        Hlosses.avg, Rlosses.avg, SumLosses.avg)\n",
        "    print(epoch_log)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhthL7xJGiUZ",
        "colab_type": "code",
        "outputId": "54e36ab5-c4fb-4cf9-cdd0-1bcec27c7e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "DATA_DIR = '/content/drive/My Drive/Deep Steg Images'\n",
        "traindir = os.path.join(DATA_DIR, 'train')\n",
        "train_dataset = ImageFolder(\n",
        "        traindir,\n",
        "        transforms.Compose([\n",
        "            transforms.Resize([256, 256]),  \n",
        "            transforms.ToTensor(),\n",
        "           ]))\n",
        "\n",
        "print(len(train_dataset))\n",
        "resultPicFrequency = 50\n",
        "trainpics = '/content/drive/My Drive/Deep Steg/train_result'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdB7JXIAIb8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Hnet = UnetGenerator(input_nc=6, output_nc=3, num_downs=7, output_function=nn.Sigmoid)\n",
        "Hnet = Hnet.cuda()\n",
        "Hnet.apply(weights_init)\n",
        "\n",
        "Rnet = RevealNet()\n",
        "Rnet = Rnet.cuda()\n",
        "Rnet.apply(weights_init)\n",
        "\n",
        "criterion = nn.MSELoss().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0M4JdgzO09y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizerH = optim.Adam(Hnet.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
        "optimizerR = optim.Adam(Rnet.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
        "num_epochs = 3\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=8)\n",
        "print(\"------------------------- training is beginning -------------------------\")\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Epoch - \", epoch + 1)\n",
        "    train(train_loader, epoch, Hnet=Hnet, Rnet=Rnet, criterion=criterion, epochs=num_epochs)\n",
        "    torch.save(Hnet.state_dict(), '/content/drive/My Drive/Deep Steg Images/output/epoch{}.pth'.format(epoch+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0hSLb4mK9gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(Hnet.state_dict(), '/content/drive/My Drive/Deep Steg Images/output/Hnet-Final.pth')\n",
        "torch.save(Rnet.state_dict(), '/content/drive/My Drive/Deep Steg Images/output/Rnet-Final.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}